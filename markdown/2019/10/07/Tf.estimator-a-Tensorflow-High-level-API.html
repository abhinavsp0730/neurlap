<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Tf.estimator, a Tensorflow High-level API | Abhinav Prakash</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Tf.estimator, a Tensorflow High-level API" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An Estimator is TensorFlow’s high-level representation of a complete model, and it has been designed for easy scaling and asynchronous training. It’s used to train the neural network model and use them to predict new data. It’s a high-level API that sits on top of the low-level core TensorFlow API. One can use a pre-made estimator or custom estimator." />
<meta property="og:description" content="An Estimator is TensorFlow’s high-level representation of a complete model, and it has been designed for easy scaling and asynchronous training. It’s used to train the neural network model and use them to predict new data. It’s a high-level API that sits on top of the low-level core TensorFlow API. One can use a pre-made estimator or custom estimator." />
<link rel="canonical" href="https://abhinavsp0730.github.io/neurlap/markdown/2019/10/07/Tf.estimator-a-Tensorflow-High-level-API.html" />
<meta property="og:url" content="https://abhinavsp0730.github.io/neurlap/markdown/2019/10/07/Tf.estimator-a-Tensorflow-High-level-API.html" />
<meta property="og:site_name" content="Abhinav Prakash" />
<meta property="og:image" content="https://abhinavsp0730.github.io/neurlap/images/article1.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-10-07T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"An Estimator is TensorFlow’s high-level representation of a complete model, and it has been designed for easy scaling and asynchronous training. It’s used to train the neural network model and use them to predict new data. It’s a high-level API that sits on top of the low-level core TensorFlow API. One can use a pre-made estimator or custom estimator.","mainEntityOfPage":{"@type":"WebPage","@id":"https://abhinavsp0730.github.io/neurlap/markdown/2019/10/07/Tf.estimator-a-Tensorflow-High-level-API.html"},"@type":"BlogPosting","url":"https://abhinavsp0730.github.io/neurlap/markdown/2019/10/07/Tf.estimator-a-Tensorflow-High-level-API.html","headline":"Tf.estimator, a Tensorflow High-level API","dateModified":"2019-10-07T00:00:00-05:00","datePublished":"2019-10-07T00:00:00-05:00","image":"https://abhinavsp0730.github.io/neurlap/images/article1.png","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/neurlap/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://abhinavsp0730.github.io/neurlap/feed.xml" title="Abhinav Prakash" /><link rel="shortcut icon" type="image/x-icon" href="/neurlap/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Tf.estimator, a Tensorflow High-level API | Abhinav Prakash</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Tf.estimator, a Tensorflow High-level API" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An Estimator is TensorFlow’s high-level representation of a complete model, and it has been designed for easy scaling and asynchronous training. It’s used to train the neural network model and use them to predict new data. It’s a high-level API that sits on top of the low-level core TensorFlow API. One can use a pre-made estimator or custom estimator." />
<meta property="og:description" content="An Estimator is TensorFlow’s high-level representation of a complete model, and it has been designed for easy scaling and asynchronous training. It’s used to train the neural network model and use them to predict new data. It’s a high-level API that sits on top of the low-level core TensorFlow API. One can use a pre-made estimator or custom estimator." />
<link rel="canonical" href="https://abhinavsp0730.github.io/neurlap/markdown/2019/10/07/Tf.estimator-a-Tensorflow-High-level-API.html" />
<meta property="og:url" content="https://abhinavsp0730.github.io/neurlap/markdown/2019/10/07/Tf.estimator-a-Tensorflow-High-level-API.html" />
<meta property="og:site_name" content="Abhinav Prakash" />
<meta property="og:image" content="https://abhinavsp0730.github.io/neurlap/images/article1.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-10-07T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"An Estimator is TensorFlow’s high-level representation of a complete model, and it has been designed for easy scaling and asynchronous training. It’s used to train the neural network model and use them to predict new data. It’s a high-level API that sits on top of the low-level core TensorFlow API. One can use a pre-made estimator or custom estimator.","mainEntityOfPage":{"@type":"WebPage","@id":"https://abhinavsp0730.github.io/neurlap/markdown/2019/10/07/Tf.estimator-a-Tensorflow-High-level-API.html"},"@type":"BlogPosting","url":"https://abhinavsp0730.github.io/neurlap/markdown/2019/10/07/Tf.estimator-a-Tensorflow-High-level-API.html","headline":"Tf.estimator, a Tensorflow High-level API","dateModified":"2019-10-07T00:00:00-05:00","datePublished":"2019-10-07T00:00:00-05:00","image":"https://abhinavsp0730.github.io/neurlap/images/article1.png","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://abhinavsp0730.github.io/neurlap/feed.xml" title="Abhinav Prakash" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/neurlap/">Abhinav Prakash</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/neurlap/articles/">Articles</a><a class="page-link" href="/neurlap/project/">Projects</a><a class="page-link" href="/neurlap/about/">About Me</a><a class="page-link" href="/neurlap/search/">Search</a><a class="page-link" href="/neurlap/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Tf.estimator, a Tensorflow High-level API</h1><p class="page-description">An Estimator is TensorFlow’s high-level representation of a complete model, and it has been designed for easy scaling and asynchronous training. It’s used to train the neural network model and use them to predict new data. It’s a high-level API that sits on top of the low-level core TensorFlow API. One can use a pre-made estimator or custom estimator.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2019-10-07T00:00:00-05:00" itemprop="datePublished">
        Oct 7, 2019
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      7 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/neurlap/categories/#markdown">markdown</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#tfestimator-a-tensorflow-high-level-api">Tf.estimator, a Tensorflow High-level API</a></li>
<li class="toc-entry toc-h2"><a href="#the-context-of-this-article-is">The context of this article is:</a></li>
<li class="toc-entry toc-h2"><a href="#what-is-tfestimator">What is tf.estimator?</a>
<ul>
<li class="toc-entry toc-h3"><a href="#1-pre-made-estimators">1. Pre-made Estimators</a></li>
<li class="toc-entry toc-h3"><a href="#2-custom-estimator">2. Custom estimator</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#tasks-for-writing-tensorflow-pre-made-estimators">Tasks for writing TensorFlow pre-made estimators.</a></li>
<li class="toc-entry toc-h2"><a href="#advantages">Advantages</a></li>
<li class="toc-entry toc-h1"><a href="#the-tfestimator-provides-some-capabilities-currently-still-under-development-for-tfkeras">The tf.estimator provides some capabilities currently still under development for tf.keras.</a>
<ul>
<li class="toc-entry toc-h2"><a href="#estimators-capabilities">Estimators capabilities</a></li>
<li class="toc-entry toc-h2"><a href="#iris-classifier-using-tfestimator">Iris classifier using tf.estimator</a>
<ul>
<li class="toc-entry toc-h3"><a href="#creating-an-input-function">Creating an input function</a></li>
<li class="toc-entry toc-h3"><a href="#define-the-feature-columns">Define the feature columns</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#instantiate-an-estimator">Instantiate an estimator</a>
<ul>
<li class="toc-entry toc-h3"><a href="#train-evaluate-and-predict">Train, Evaluate, and Predict</a></li>
<li class="toc-entry toc-h3"><a href="#making-predictions-inferring-from-the-trained-model">Making predictions (inferring) from the trained model</a></li>
<li class="toc-entry toc-h3"><a href="#refrences--tensorflows-official-documentation">Refrences:- Tensorflow’s official Documentation</a></li>
</ul>
</li>
</ul>
</li>
</ul><h2 id="tfestimator-a-tensorflow-high-level-api">
<a class="anchor" href="#tfestimator-a-tensorflow-high-level-api" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tf.estimator, a Tensorflow High-level API</h2>

<p><img src="https://cdn-images-1.medium.com/max/2460/1*FyA1WjY8wC4p5eIt43jTHA.png" alt=""></p>

<p>Now Tensorflow 2.0 has been officially released and it’s having two high-level deep learning APIs.
The first one is tf.keras and another one is tf.estimator. You can see the list of TensorFlow’s Python API in the picture above. Some of you are familiar with building an ML model using Keras. But we’re not so familiar with tf.estimator (Assuming we refer to a beginner in ML).
So let us understand tf.estimator.</p>

<h2 id="the-context-of-this-article-is">
<a class="anchor" href="#the-context-of-this-article-is" aria-hidden="true"><span class="octicon octicon-link"></span></a>The context of this article is:</h2>
<blockquote>
  <ol>
    <li>Giving you an idea about what tf.estimator is all about.
2.What tasks we’ve to follow while writing the TensorFlow program based on Estimators(pre-made Estimators).</li>
    <li>Advantages .
4.Estimators capabilities.</li>
    <li>We’re going to build and test a model by using tf.estimator that classifies iris flowers into there species.</li>
  </ol>
</blockquote>

<h2 id="what-is-tfestimator">
<a class="anchor" href="#what-is-tfestimator" aria-hidden="true"><span class="octicon octicon-link"></span></a>What is tf.estimator?</h2>

<p>An Estimator is TensorFlow’s high-level representation of a complete model, and it has been designed for easy scaling and asynchronous training. It’s used to train the neural network model and use them to predict new data. It’s a high-level API that sits on top of the low-level core TensorFlow API.
One can use a pre-made estimator or custom estimator.</p>

<h3 id="1-pre-made-estimators">
<a class="anchor" href="#1-pre-made-estimators" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Pre-made Estimators</h3>

<p>Pre-made Estimators enable you to work at a much higher conceptual level than the base TensorFlow APIs. You no longer have to worry about creating the computational graph or sessions since Estimators handle all the “plumbing” for you. Furthermore, pre-made Estimators let you experiment with different model architectures by making only minimal code changes. tf.estimator. DNNClassifier, for example, is a pre-made Estimator class that trains classification models based on dense, feed-forward neural networks.</p>

<h3 id="2-custom-estimator">
<a class="anchor" href="#2-custom-estimator" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Custom estimator</h3>

<p>The heart of every Estimator — whether pre-made or custom — is its model function, which is a method that builds graphs for training, evaluation, and prediction. When you are using a pre-made Estimator, someone else has already implemented the model function. When relying on a custom Estimator, you must write the model function yourself.
In this model, we’re mainly dealing with pre-made estimators</p>

<h2 id="tasks-for-writing-tensorflow-pre-made-estimators">
<a class="anchor" href="#tasks-for-writing-tensorflow-pre-made-estimators" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tasks for writing TensorFlow pre-made estimators.</h2>

<p><img src="https://cdn-images-1.medium.com/max/2124/1*cv-u3ZwrOYiYlGzh1Yhz0g.png" alt="Source. [https://torres.ai](https://torres.ai)"></p>
<blockquote>
  <p>1.Create one or more input functions.</p>
  <ol>
    <li>Define the model’s feature columns.</li>
    <li>Instantiate an Estimator, specifying the feature columns and various hyperparameters.</li>
    <li>Call one or more methods on the Estimator object, passing the appropriate input function as the source of the data.</li>
  </ol>
</blockquote>

<p>Later in this article, we’re going to implement the above tasks for iris classification.</p>

<h2 id="advantages">
<a class="anchor" href="#advantages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Advantages</h2>
<blockquote>
  <h1 id="the-tfestimator-provides-some-capabilities-currently-still-under-development-for-tfkeras">
<a class="anchor" href="#the-tfestimator-provides-some-capabilities-currently-still-under-development-for-tfkeras" aria-hidden="true"><span class="octicon octicon-link"></span></a>The tf.estimator provides some capabilities currently still under development for tf.keras.</h1>
  <p>#These are:-
#1.We can conduct distributed training across multiple servers with the Estimators API
#2.Full TFX integration.
#TensorFlow Extended (TFX) is an end-to-end platform for deploying production ML pipelines. The tf.estimator is supported for fully TFX integration.</p>
</blockquote>

<h2 id="estimators-capabilities">
<a class="anchor" href="#estimators-capabilities" aria-hidden="true"><span class="octicon octicon-link"></span></a>Estimators capabilities</h2>

<p>Estimators provide the following benefits:</p>

<ol>
  <li>
    <p>You can run Estimator-based models on a localhost or a distributed multi-server environment without changing your model. Furthermore, you can run Estimator-based models on CPUs, GPUs, or TPUs without recoding your model.</p>
  </li>
  <li>
    <p>Estimators provide a safely distributed training loop that controls how and when to:
 (a)load data
 (b)handle exceptions
 ©create checkpoint files and recover from failures
 (d)save summaries for TensorBoard</p>
  </li>
</ol>

<h2 id="iris-classifier-using-tfestimator">
<a class="anchor" href="#iris-classifier-using-tfestimator" aria-hidden="true"><span class="octicon octicon-link"></span></a>Iris classifier using tf.estimator</h2>

<p>We’re going to build an iris classifier using tf.estimator. The dataset we’re using is iris data set which is having four features sepal length, sepal width, petal length &amp; petal width and three labels Setosa, Versicolor &amp; Virginica.
But first, we import all the dependencies</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from __future__ import absolute_import, division, print_function, unicode_literals


import tensorflow as tf

import pandas as pd
</code></pre></div></div>

<p>And then we preprocess the data to perform the following task:-</p>

<p>(a)Create one or more input functions.
 (b)Define the model’s feature columns.
 (c )Instantiate an Estimator, specifying the feature columns and various hyperparameters.
 (d)Call one or more methods on the Estimator object, passing the appropriate input function as the source of the data.</p>

<p><strong>Preprocessing the data</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']
SPECIES = ['Setosa', 'Versicolor', 'Virginica']
</code></pre></div></div>

<p>Downloading the data set.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>train_path = tf.keras.utils.get_file(
    "iris_training.csv", "https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv")
test_path = tf.keras.utils.get_file(
    "iris_test.csv", "https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv")

train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)
test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)
</code></pre></div></div>

<h3 id="creating-an-input-function">
<a class="anchor" href="#creating-an-input-function" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating an input function</h3>

<p>You must create input functions to supply data for training, evaluating, and prediction.</p>

<p>An input function is a function that returns a tf.data.Dataset object which outputs the following two-element tuple:</p>

<p>features — A Python dictionary in which:
 (a)Each key is the name of a feature.
 (b)Each value is an array containing all of that feature’s values.
 label — An array containing the values of the label for every example.
We’re using pandas for building input pipeline</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def input_fn(features, labels, training=True, batch_size=256):
    """An input function for training or evaluating"""
    # Convert the inputs to a Dataset.
    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))

    # Shuffle and repeat if you are in training mode.
    if training:
        dataset = dataset.shuffle(1000).repeat()
    
    return dataset.batch(batch_size)
</code></pre></div></div>

<h3 id="define-the-feature-columns">
<a class="anchor" href="#define-the-feature-columns" aria-hidden="true"><span class="octicon octicon-link"></span></a>Define the feature columns</h3>

<p>A feature column is an object describing how the model should use raw input data from the features dictionary. When you build an Estimator model, we pass it a list of feature columns that describe each of the features you want the model to use. The tf.feature_column module provides many options for representing data to the model.</p>

<p>For Iris, the 4 raw features are numeric values, so we’ll build a list of feature columns to tell the Estimator model to represent each of the four features as 32-bit floating-point values. Therefore, the code to create the feature column is:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Feature columns describe how to use the input.
my_feature_columns = []
for key in train.keys():
    my_feature_columns.append(tf.feature_column.numeric_column(key=key))
</code></pre></div></div>

<h2 id="instantiate-an-estimator">
<a class="anchor" href="#instantiate-an-estimator" aria-hidden="true"><span class="octicon octicon-link"></span></a>Instantiate an estimator</h2>

<p>The Iris problem is a classic classification problem. Fortunately, TensorFlow provides several pre-made classifier Estimators, including:</p>

<p>a. tf.estimator.DNNClassifier for deep models that perform multi-class classification.
 b. tf.estimator.DNNLinearCombinedClassifier for wide &amp; deep models.
 c. tf.estimator.LinearClassifier for classifiers based on linear models.</p>

<p>For the Iris problem, tf.estimator.DNNClassifier seems like the best choice. Here’s how we instantiated this Estimator:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.
classifier = tf.estimator.DNNClassifier(
    feature_columns=my_feature_columns,
    # Two hidden layers of 10 nodes each.
    hidden_units=[30, 10],
    # The model must choose between 3 classes.
    n_classes=3)
</code></pre></div></div>

<h3 id="train-evaluate-and-predict">
<a class="anchor" href="#train-evaluate-and-predict" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train, Evaluate, and Predict</h3>

<p><em>Train the model</em>
Train the model by calling the Estimator’s train method as follows:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Train the Model.
classifier.train(
    input_fn=lambda: input_fn(train, train_y, training=True),
    steps=5000)
</code></pre></div></div>

<p>Evaluate</p>

<p>Now that the model has been trained, you can get some statistics on its performance. The following code block evaluates the accuracy of the trained model on the test data:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>eval_result = classifier.evaluate(
    input_fn=lambda: input_fn(test, test_y, training=False))

print('\nTest set accuracy: {accuracy:0.3f}\n'.format(**eval_result))
</code></pre></div></div>

<p>After evaluating it we’ll get an accuracy of about 56%</p>

<h3 id="making-predictions-inferring-from-the-trained-model">
<a class="anchor" href="#making-predictions-inferring-from-the-trained-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Making predictions (inferring) from the trained model</h3>

<p>You now have a trained model that produces good evaluation results. You can now use the trained model to predict the species of an Iris flower based on some unlabeled measurements. As with training and evaluation, you make predictions using a single function call:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Generate predictions from the model
expected = ['Setosa', 'Versicolor', 'Virginica']
predict_x = {
    'SepalLength': [5.1, 5.9, 6.9],
    'SepalWidth': [3.3, 3.0, 3.1],
    'PetalLength': [1.7, 4.2, 5.4],
    'PetalWidth': [0.5, 1.5, 2.1],
}

def input_fn(features, batch_size=256):
    """An input function for prediction."""
    # Convert the inputs to a Dataset without labels.
    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)

predictions = classifier.predict(
    input_fn=lambda: input_fn(predict_x))
</code></pre></div></div>

<p>The predict method returns a Python iterable, yielding a dictionary of prediction results for each example. The following code prints a few predictions and their probabilities:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for pred_dict, expec in zip(predictions, expected):
    class_id = pred_dict['class_ids'][0]
    probability = pred_dict['probabilities'][class_id]

    print('Prediction is "{}" ({:.1f}%), expected "{}"'.format(
        SPECIES[class_id], 100 * probability, expec))
</code></pre></div></div>

<p>We’ll get an output like this</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /tmp/tmpy5w5zoj8/model.ckpt-5000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
Prediction is "Setosa" (73.0%), expected "Setosa"
Prediction is "Virginica" (42.6%), expected "Versicolor"
Prediction is "Virginica" (49.0%), expected "Virginica"
</code></pre></div></div>

<h3 id="refrences--tensorflows-official-documentation">
<a class="anchor" href="#refrences--tensorflows-official-documentation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Refrences:- Tensorflow’s official Documentation</h3>

<p>Hope you like this article</p>

<p>Do you know what, you can hit the clap button 50 times in medium?
If you like this blog, show some love by doing claps.</p>

<p><img src="https://cdn-images-1.medium.com/max/2000/1*HnhqbqJ1vlHFEZmO5oEtqQ.gif" alt=""></p>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="abhinavsp0730/neurlap"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/neurlap/markdown/2019/10/07/Tf.estimator-a-Tensorflow-High-level-API.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/neurlap/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/neurlap/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/neurlap/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/abhinavsp0730" title="abhinavsp0730"><svg class="svg-icon grey"><use xlink:href="/neurlap/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/abhinav-prakash-706902171" title="abhinav-prakash-706902171"><svg class="svg-icon grey"><use xlink:href="/neurlap/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/neurlap" title="neurlap"><svg class="svg-icon grey"><use xlink:href="/neurlap/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
